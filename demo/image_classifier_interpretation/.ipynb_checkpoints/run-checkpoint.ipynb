{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "ename": "NotFoundError",
     "evalue": "/mnt/gradio/demo/image_classifier_interpretation/model_dw/config.json; No such file or directory",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNotFoundError\u001b[0m                             Traceback (most recent call last)",
      "Input \u001b[0;32mIn [5]\u001b[0m, in \u001b[0;36m<cell line: 22>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     21\u001b[0m model_dir \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124m/mnt/gradio/demo/image_classifier_interpretation/model_dw\u001b[39m\u001b[38;5;124m'\u001b[39m \u001b[38;5;66;03m#@param\u001b[39;00m\n\u001b[1;32m     22\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m tf\u001b[38;5;241m.\u001b[39mio\u001b[38;5;241m.\u001b[39mgfile\u001b[38;5;241m.\u001b[39mGFile(os\u001b[38;5;241m.\u001b[39mpath\u001b[38;5;241m.\u001b[39mjoin(model_dir, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mconfig.json\u001b[39m\u001b[38;5;124m'\u001b[39m), \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mr\u001b[39m\u001b[38;5;124m'\u001b[39m) \u001b[38;5;28;01mas\u001b[39;00m f:\n\u001b[0;32m---> 23\u001b[0m   config \u001b[38;5;241m=\u001b[39m ml_collections\u001b[38;5;241m.\u001b[39mConfigDict(json\u001b[38;5;241m.\u001b[39mloads(\u001b[43mf\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mread\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m))\n\u001b[1;32m     25\u001b[0m \u001b[38;5;66;03m# Set batch size to 1.\u001b[39;00m\n\u001b[1;32m     26\u001b[0m config\u001b[38;5;241m.\u001b[39meval\u001b[38;5;241m.\u001b[39mbatch_size \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1\u001b[39m\n",
      "File \u001b[0;32m/usr/local/lib/python3.8/dist-packages/tensorflow/python/lib/io/file_io.py:114\u001b[0m, in \u001b[0;36mFileIO.read\u001b[0;34m(self, n)\u001b[0m\n\u001b[1;32m    102\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mread\u001b[39m(\u001b[38;5;28mself\u001b[39m, n\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m):\n\u001b[1;32m    103\u001b[0m   \u001b[38;5;124;03m\"\"\"Returns the contents of a file as a string.\u001b[39;00m\n\u001b[1;32m    104\u001b[0m \n\u001b[1;32m    105\u001b[0m \u001b[38;5;124;03m  Starts reading from current position in file.\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    112\u001b[0m \u001b[38;5;124;03m    string if in string (regular) mode.\u001b[39;00m\n\u001b[1;32m    113\u001b[0m \u001b[38;5;124;03m  \"\"\"\u001b[39;00m\n\u001b[0;32m--> 114\u001b[0m   \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_preread_check\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    115\u001b[0m   \u001b[38;5;28;01mif\u001b[39;00m n \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m:\n\u001b[1;32m    116\u001b[0m     length \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39msize() \u001b[38;5;241m-\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtell()\n",
      "File \u001b[0;32m/usr/local/lib/python3.8/dist-packages/tensorflow/python/lib/io/file_io.py:76\u001b[0m, in \u001b[0;36mFileIO._preread_check\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m     73\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_read_check_passed:\n\u001b[1;32m     74\u001b[0m   \u001b[38;5;28;01mraise\u001b[39;00m errors\u001b[38;5;241m.\u001b[39mPermissionDeniedError(\u001b[38;5;28;01mNone\u001b[39;00m, \u001b[38;5;28;01mNone\u001b[39;00m,\n\u001b[1;32m     75\u001b[0m                                      \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mFile isn\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mt open for reading\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m---> 76\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_read_buf \u001b[38;5;241m=\u001b[39m \u001b[43m_pywrap_file_io\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mBufferedInputStream\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m     77\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcompat\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mpath_to_str\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m__name\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m1024\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;241;43m512\u001b[39;49m\u001b[43m)\u001b[49m\n",
      "\u001b[0;31mNotFoundError\u001b[0m: /mnt/gradio/demo/image_classifier_interpretation/model_dw/config.json; No such file or directory"
     ]
    }
   ],
   "source": [
    "import requests\n",
    "import tensorflow as tf\n",
    "import os\n",
    "import sys\n",
    "import numpy as np\n",
    "from PIL import Image\n",
    "import json\n",
    "\n",
    "sys.path.append(os.getcwd())\n",
    "root_dir = os.getcwd()\n",
    "sys.path.insert(1,root_dir) \n",
    "\n",
    "import ml_collections\n",
    "from models import ar_model as model_lib\n",
    "from data import data_utils\n",
    "from tasks.object_detection import TaskObjectDetection\n",
    "from tasks.visualization import vis_utils\n",
    "import gradio as gr\n",
    "\n",
    "#@title Load model.\n",
    "model_dir = '/mnt/gradio/demo/image_classifier_interpretation/model_dw' #@param\n",
    "with tf.io.gfile.GFile(os.path.join(model_dir, 'config.json'), 'r') as f:\n",
    "  config = ml_collections.ConfigDict(json.loads(f.read()))\n",
    "\n",
    "# Set batch size to 1.\n",
    "config.eval.batch_size = 1\n",
    "\n",
    "# Remove the annotation filepaths.\n",
    "config.dataset.coco_annotations_dir = None\n",
    "\n",
    "# Update config fields.\n",
    "config.task.vocab_id = 10  # object_detection task vocab id.\n",
    "config.training = False\n",
    "config.dataset.val_filename='instances_val2017.json'\n",
    "\n",
    "assert config.task.name == \"object_detection\"\n",
    "task = TaskObjectDetection(config)\n",
    "\n",
    "# Restore checkpoint.\n",
    "model = model_lib.Model(config)\n",
    "checkpoint = tf.train.Checkpoint(\n",
    "    model=model, global_step=tf.Variable(0, dtype=tf.int64))\n",
    "ckpt = tf.train.latest_checkpoint(model_dir)\n",
    "checkpoint.restore(ckpt).expect_partial()\n",
    "global_step = checkpoint.global_step\n",
    "\n",
    "#@title Category names for COCO.\n",
    "categories_str = '{\"categories\": [{\"supercategory\": \"person\",\"id\": 1,\"name\": \"person\"},{\"supercategory\": \"vehicle\",\"id\": 2,\"name\": \"bicycle\"},{\"supercategory\": \"vehicle\",\"id\": 3,\"name\": \"car\"},{\"supercategory\": \"vehicle\",\"id\": 4,\"name\": \"motorcycle\"},{\"supercategory\": \"vehicle\",\"id\": 5,\"name\": \"airplane\"},{\"supercategory\": \"vehicle\",\"id\": 6,\"name\": \"bus\"},{\"supercategory\": \"vehicle\",\"id\": 7,\"name\": \"train\"},{\"supercategory\": \"vehicle\",\"id\": 8,\"name\": \"truck\"},{\"supercategory\": \"vehicle\",\"id\": 9,\"name\": \"boat\"},{\"supercategory\": \"outdoor\",\"id\": 10,\"name\": \"traffic light\"},{\"supercategory\": \"outdoor\",\"id\": 11,\"name\": \"fire hydrant\"},{\"supercategory\": \"outdoor\",\"id\": 13,\"name\": \"stop sign\"},{\"supercategory\": \"outdoor\",\"id\": 14,\"name\": \"parking meter\"},{\"supercategory\": \"outdoor\",\"id\": 15,\"name\": \"bench\"},{\"supercategory\": \"animal\",\"id\": 16,\"name\": \"bird\"},{\"supercategory\": \"animal\",\"id\": 17,\"name\": \"cat\"},{\"supercategory\": \"animal\",\"id\": 18,\"name\": \"dog\"},{\"supercategory\": \"animal\",\"id\": 19,\"name\": \"horse\"},{\"supercategory\": \"animal\",\"id\": 20,\"name\": \"sheep\"},{\"supercategory\": \"animal\",\"id\": 21,\"name\": \"cow\"},{\"supercategory\": \"animal\",\"id\": 22,\"name\": \"elephant\"},{\"supercategory\": \"animal\",\"id\": 23,\"name\": \"bear\"},{\"supercategory\": \"animal\",\"id\": 24,\"name\": \"zebra\"},{\"supercategory\": \"animal\",\"id\": 25,\"name\": \"giraffe\"},{\"supercategory\": \"accessory\",\"id\": 27,\"name\": \"backpack\"},{\"supercategory\": \"accessory\",\"id\": 28,\"name\": \"umbrella\"},{\"supercategory\": \"accessory\",\"id\": 31,\"name\": \"handbag\"},{\"supercategory\": \"accessory\",\"id\": 32,\"name\": \"tie\"},{\"supercategory\": \"accessory\",\"id\": 33,\"name\": \"suitcase\"},{\"supercategory\": \"sports\",\"id\": 34,\"name\": \"frisbee\"},{\"supercategory\": \"sports\",\"id\": 35,\"name\": \"skis\"},{\"supercategory\": \"sports\",\"id\": 36,\"name\": \"snowboard\"},{\"supercategory\": \"sports\",\"id\": 37,\"name\": \"sports ball\"},{\"supercategory\": \"sports\",\"id\": 38,\"name\": \"kite\"},{\"supercategory\": \"sports\",\"id\": 39,\"name\": \"baseball bat\"},{\"supercategory\": \"sports\",\"id\": 40,\"name\": \"baseball glove\"},{\"supercategory\": \"sports\",\"id\": 41,\"name\": \"skateboard\"},{\"supercategory\": \"sports\",\"id\": 42,\"name\": \"surfboard\"},{\"supercategory\": \"sports\",\"id\": 43,\"name\": \"tennis racket\"},{\"supercategory\": \"kitchen\",\"id\": 44,\"name\": \"bottle\"},{\"supercategory\": \"kitchen\",\"id\": 46,\"name\": \"wine glass\"},{\"supercategory\": \"kitchen\",\"id\": 47,\"name\": \"cup\"},{\"supercategory\": \"kitchen\",\"id\": 48,\"name\": \"fork\"},{\"supercategory\": \"kitchen\",\"id\": 49,\"name\": \"knife\"},{\"supercategory\": \"kitchen\",\"id\": 50,\"name\": \"spoon\"},{\"supercategory\": \"kitchen\",\"id\": 51,\"name\": \"bowl\"},{\"supercategory\": \"food\",\"id\": 52,\"name\": \"banana\"},{\"supercategory\": \"food\",\"id\": 53,\"name\": \"apple\"},{\"supercategory\": \"food\",\"id\": 54,\"name\": \"sandwich\"},{\"supercategory\": \"food\",\"id\": 55,\"name\": \"orange\"},{\"supercategory\": \"food\",\"id\": 56,\"name\": \"broccoli\"},{\"supercategory\": \"food\",\"id\": 57,\"name\": \"carrot\"},{\"supercategory\": \"food\",\"id\": 58,\"name\": \"hot dog\"},{\"supercategory\": \"food\",\"id\": 59,\"name\": \"pizza\"},{\"supercategory\": \"food\",\"id\": 60,\"name\": \"donut\"},{\"supercategory\": \"food\",\"id\": 61,\"name\": \"cake\"},{\"supercategory\": \"furniture\",\"id\": 62,\"name\": \"chair\"},{\"supercategory\": \"furniture\",\"id\": 63,\"name\": \"couch\"},{\"supercategory\": \"furniture\",\"id\": 64,\"name\": \"potted plant\"},{\"supercategory\": \"furniture\",\"id\": 65,\"name\": \"bed\"},{\"supercategory\": \"furniture\",\"id\": 67,\"name\": \"dining table\"},{\"supercategory\": \"furniture\",\"id\": 70,\"name\": \"toilet\"},{\"supercategory\": \"electronic\",\"id\": 72,\"name\": \"tv\"},{\"supercategory\": \"electronic\",\"id\": 73,\"name\": \"laptop\"},{\"supercategory\": \"electronic\",\"id\": 74,\"name\": \"mouse\"},{\"supercategory\": \"electronic\",\"id\": 75,\"name\": \"remote\"},{\"supercategory\": \"electronic\",\"id\": 76,\"name\": \"keyboard\"},{\"supercategory\": \"electronic\",\"id\": 77,\"name\": \"cell phone\"},{\"supercategory\": \"appliance\",\"id\": 78,\"name\": \"microwave\"},{\"supercategory\": \"appliance\",\"id\": 79,\"name\": \"oven\"},{\"supercategory\": \"appliance\",\"id\": 80,\"name\": \"toaster\"},{\"supercategory\": \"appliance\",\"id\": 81,\"name\": \"sink\"},{\"supercategory\": \"appliance\",\"id\": 82,\"name\": \"refrigerator\"},{\"supercategory\": \"indoor\",\"id\": 84,\"name\": \"book\"},{\"supercategory\": \"indoor\",\"id\": 85,\"name\": \"clock\"},{\"supercategory\": \"indoor\",\"id\": 86,\"name\": \"vase\"},{\"supercategory\": \"indoor\",\"id\": 87,\"name\": \"scissors\"},{\"supercategory\": \"indoor\",\"id\": 88,\"name\": \"teddy bear\"},{\"supercategory\": \"indoor\",\"id\": 89,\"name\": \"hair drier\"},{\"supercategory\": \"indoor\",\"id\": 90,\"name\": \"toothbrush\"}]}'\n",
    "categories_dict = json.loads(categories_str)\n",
    "categories_dict = {c['id']: c for c in categories_dict['categories']}\n",
    "\n",
    "url = 'http://images.cocodataset.org/val2017/000000039769.jpg' #@param\n",
    "\n",
    "im = Image.open(requests.get(url, stream=True).raw)\n",
    "im\n",
    "\n",
    "num_instances_to_generate = 10 #@param\n",
    "min_score_thresh = 0.5 #@param\n",
    "\n",
    "# Build inference graph.\n",
    "task.config.task.max_instances_per_image_test = num_instances_to_generate\n",
    "@tf.function\n",
    "def infer(model, preprocessed_outputs):\n",
    "  return task.infer(model, preprocessed_outputs)\n",
    "\n",
    "# Construct features and dummy labels.\n",
    "im = np.array(im)\n",
    "features = {\n",
    "    'image': tf.image.convert_image_dtype(im, tf.float32),\n",
    "    'image/id': 0, # dummy image id.\n",
    "    'orig_image_size': tf.shape(im)[0:2],\n",
    "}\n",
    "labels = {\n",
    "    'label': tf.zeros([1], tf.int32),\n",
    "    'bbox': tf.zeros([1, 4]),\n",
    "    'area': tf.zeros([1]),\n",
    "    'is_crowd': tf.zeros([1]),\n",
    "}\n",
    "features, labels = data_utils.preprocess_eval(\n",
    "    features,\n",
    "    labels,\n",
    "    max_image_size=config.model.image_size,\n",
    "    max_instances_per_image=1)\n",
    "\n",
    "# Batch features and labels.\n",
    "features = {\n",
    "    k: tf.expand_dims(v, 0) for k, v in features.items()\n",
    "}\n",
    "labels = {\n",
    "    k: tf.expand_dims(v, 0) for k, v in labels.items()\n",
    "}\n",
    "# Inference.\n",
    "preprocessed_outputs = (features['image'], None, (features, labels))\n",
    "infer_outputs = infer(model, preprocessed_outputs)\n",
    "_, pred_seq, _ = infer_outputs\n",
    "results = task.postprocess_tpu(*infer_outputs)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "inception_net = tf.keras.applications.MobileNetV2()  # load the model\n",
    "\n",
    "# Download human-readable labels for ImageNet.\n",
    "response = requests.get(\"https://git.io/JJkYN\")\n",
    "labels = response.text.split(\"\\n\")\n",
    "\n",
    "\n",
    "def classify_image(inp):\n",
    "    inp = inp.reshape((-1, 224, 224, 3))\n",
    "    inp = tf.keras.applications.mobilenet_v2.preprocess_input(inp)\n",
    "    prediction = inception_net.predict(inp).flatten()\n",
    "    # return {labels[i]: float(prediction[i]) for i in range(1000)}\n",
    "    return 'punks.png'\n",
    "\n",
    "\n",
    "image = gr.inputs.Image(shape=(224, 224))\n",
    "label = gr.outputs.Label(num_top_classes=3)\n",
    "\n",
    "gr.Interface(\n",
    "    # fn=classify_image, inputs=image, outputs=label, interpretation=\"default\"\n",
    "    fn=classify_image, \n",
    "    inputs=image, \n",
    "    outputs=\"image\", \n",
    "    interpretation=\"default\"\n",
    ").launch()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "dir = '/mnt/gradio/demo/image_classifier_interpretation/model_dw'"
   ]
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
